{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CYoCgoYJuQ_O"
   },
   "source": [
    "# HW2: Classification\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "--YDgNJ0vVCF"
   },
   "source": [
    "## Name: Mohammad Mahdi Heydari Nasab\n",
    "## Student ID: 99105389"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "BgvuH9BFuQ_P"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\ten\\anaconda3\\lib\\site-packages (4.3.0)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\ten\\anaconda3\\lib\\site-packages (from gensim) (1.7.1)\n",
      "Requirement already satisfied: FuzzyTM>=0.4.0 in c:\\users\\ten\\anaconda3\\lib\\site-packages (from gensim) (2.0.5)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\ten\\anaconda3\\lib\\site-packages (from gensim) (1.20.3)\n",
      "Requirement already satisfied: Cython==0.29.32 in c:\\users\\ten\\anaconda3\\lib\\site-packages (from gensim) (0.29.32)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\ten\\anaconda3\\lib\\site-packages (from gensim) (6.3.0)\n",
      "Requirement already satisfied: pyfume in c:\\users\\ten\\anaconda3\\lib\\site-packages (from FuzzyTM>=0.4.0->gensim) (0.2.25)\n",
      "Requirement already satisfied: pandas in c:\\users\\ten\\anaconda3\\lib\\site-packages (from FuzzyTM>=0.4.0->gensim) (1.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\ten\\anaconda3\\lib\\site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\ten\\anaconda3\\lib\\site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ten\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas->FuzzyTM>=0.4.0->gensim) (1.16.0)\n",
      "Requirement already satisfied: simpful in c:\\users\\ten\\anaconda3\\lib\\site-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (2.9.0)\n",
      "Requirement already satisfied: fst-pso in c:\\users\\ten\\anaconda3\\lib\\site-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (1.8.1)\n",
      "Requirement already satisfied: miniful in c:\\users\\ten\\anaconda3\\lib\\site-packages (from fst-pso->pyfume->FuzzyTM>=0.4.0->gensim) (0.0.6)\n",
      "Requirement already satisfied: requests in c:\\users\\ten\\anaconda3\\lib\\site-packages (from simpful->pyfume->FuzzyTM>=0.4.0->gensim) (2.26.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ten\\anaconda3\\lib\\site-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ten\\anaconda3\\lib\\site-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\ten\\anaconda3\\lib\\site-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ten\\anaconda3\\lib\\site-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (3.2)\n"
     ]
    }
   ],
   "source": [
    "# Install the dependencies you use in the notebook here:\n",
    "import nltk\n",
    "!pip install gensim\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import wordnet\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from evaluation import *\n",
    "from tqdm import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3EFR0cx2aIsU"
   },
   "source": [
    "# 0. GloVe Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2oCGP-9idAr_"
   },
   "source": [
    "In this section we will prepare GloVe embeddings for our classification task.\n",
    "First we will download the embeddings file, then we will initialize a word2vec based on GloVe embeddings.\n",
    "\n",
    "Finally we will write a funcation to produce the text's GloVe embeddings.\n",
    "\n",
    "GloVe embeddings are available in diferent vector sizes, for this assignment we will use the 50d version.\n",
    "\n",
    "You can read more about GloVe embeddings in [this Medium post](https://towardsdatascience.com/light-on-math-ml-intuitive-guide-to-understanding-glove-embeddings-b13b4f19c010)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zqIMRJP_kQOh"
   },
   "source": [
    "## 0.0. Preprocessing\n",
    "use the preprocessing functions from your last homework to define the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "w6FChNgQkaoM"
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Gets a text and returns the preprocessed version of it.\n",
    "\n",
    "    Parameters:\n",
    "        text (str): input text\n",
    "\n",
    "    Returns:\n",
    "        text (str): preprocessed text\n",
    "    \"\"\"\n",
    "    punctuations = \"``''?:!.,;،؛؟#\"\n",
    "    text = text.lower()\n",
    "    text = nltk.tokenize.word_tokenize(text)\n",
    "    text = [word for word in text if word not in punctuations]\n",
    "    english_stopwords = set(stopwords.words('english'))\n",
    "    text = [word for word in text if word not in english_stopwords]\n",
    "    english_lemmatizer = wordnet.WordNetLemmatizer()\n",
    "    text = [english_lemmatizer.lemmatize(word) for word in text]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "daGQDfBqkwh9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dude', 'imagine', 'bug', 'accidentally', 'getting', 'stuck', 'car', 'driving', 'far', 'af', 'away', 'everything', 'know']\n"
     ]
    }
   ],
   "source": [
    "def test_preprocess_text():\n",
    "    text = \"Dude! imagine being a #bug\\n and accidentally getting STUCK! in a #car and   driving far af away from everything you know!!!\"\n",
    "    try:\n",
    "        print(preprocess_text(text))\n",
    "    except NotImplementedError:\n",
    "        print(\"Run this cell after implementation of the above cell!\")\n",
    "\n",
    "test_preprocess_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ML6C3Ln5d9cN"
   },
   "source": [
    "## 0.1. Download Data\n",
    "Download the GloVe data using the cell below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "k05nITesZBEm"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SYSTEM_WGETRC = c:/progra~1/wget/etc/wgetrc\n",
      "syswgetrc = C:\\Program Files (x86)\\GnuWin32/etc/wgetrc\n",
      "--2023-02-04 14:40:42--  http://nlp.stanford.edu/data/glove.6B.zip\n",
      "Resolving nlp.stanford.edu... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
      "--2023-02-04 14:40:43--  https://nlp.stanford.edu/data/glove.6B.zip\n",
      "Connecting to nlp.stanford.edu|171.64.67.140|:443... connected.\n",
      "ERROR: cannot verify nlp.stanford.edu's certificate, issued by `/C=US/ST=MI/L=Ann Arbor/O=Internet2/OU=InCommon/CN=InCommon RSA Server CA':\n",
      "  Self-signed certificate encountered.\n",
      "To connect to nlp.stanford.edu insecurely, use `--no-check-certificate'.\n",
      "Unable to establish SSL connection.\n",
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "!unzip -q glove.6B.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eWDPdNC8vjsr"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YFG0wNG1eOVv"
   },
   "source": [
    "## 0.2. Make glove model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "sqHO0FwweKLy"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ten\\AppData\\Local\\Temp/ipykernel_15320/3129010610.py:5: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
      "  glove2word2vec(glove_input_file, word2vec_output_file)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(400000, 50)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "glove_input_file = 'glove.6B.50d.txt'\n",
    "word2vec_output_file = 'glove.6B.50d.txt.word2vec'\n",
    "glove2word2vec(glove_input_file, word2vec_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ZemnqQuQeUm0"
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors # load the Stanford GloVe model\n",
    "\n",
    "filename = 'glove.6B.50d.txt.word2vec'\n",
    "model = KeyedVectors.load_word2vec_format(filename, binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pHqaTK4xf_4H"
   },
   "source": [
    "## 0.3. Word embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "9Ur-CtSZgDyJ"
   },
   "outputs": [],
   "source": [
    "def get_token_embedding(token):\n",
    "    \"\"\"\n",
    "    Gets a token and returns its GloVe embedding.\n",
    "\n",
    "    Parameters:\n",
    "        token (str): input token\n",
    "\n",
    "    Returns:\n",
    "        embedding_vector (np.array): embedding vector in numpy format.\n",
    "    \"\"\"\n",
    "    if model.__contains__(token):\n",
    "        return model.get_vector(token, norm = True)\n",
    "    else:\n",
    "        return np.zeros((50,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "WJHyDq4dgdYI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding of frog :\n",
      "  [ 0.12718841 -0.04325256 -0.14992847  0.1860879   0.06768462  0.15954083\n",
      "  0.03779937 -0.06894321  0.16497736 -0.06598011  0.00232193  0.09462761\n",
      "  0.33323455  0.00281182 -0.01951356  0.04010192  0.05230232  0.23498537\n",
      " -0.22706708 -0.08941196 -0.23602724 -0.18850714  0.11704467 -0.01218248\n",
      "  0.20852165 -0.08130198 -0.08681977  0.15361671 -0.11215618 -0.20002617\n",
      "  0.14154759 -0.12305214  0.02793902  0.11309178 -0.07629679  0.00312105\n",
      " -0.05201059 -0.16896775  0.01644189 -0.20327474 -0.13834901 -0.03856619\n",
      " -0.1816495   0.06414223  0.26753366 -0.03101465  0.12956388 -0.31443903\n",
      "  0.03038536 -0.06601761]\n"
     ]
    }
   ],
   "source": [
    "def test_get_token_embedding():\n",
    "    token = \"frog\"\n",
    "    try:\n",
    "        assert get_token_embedding(token).shape == (50,), \"Wrong embedding initialization\"\n",
    "    except NotImplementedError:\n",
    "        print(\"Run this cell after implementation of the above cell!\")\n",
    "    print('Embedding of', token, ':\\n ', get_token_embedding(token))\n",
    "\n",
    "test_get_token_embedding()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "suO6a_xJeoaB"
   },
   "source": [
    "## 0.4. Vectorize input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "qEWrBSyJejUu"
   },
   "outputs": [],
   "source": [
    "def vectorize_text(tokens):\n",
    "    \"\"\"\n",
    "    Gets a list of tokens and returns the average GloVe\n",
    "    embedding of all the tokens.\n",
    "\n",
    "    Parameters:\n",
    "        tokens (List(str)): list of input tokens\n",
    "\n",
    "    Returns:\n",
    "        embedding_vector (np.array): embedding vector in numpy format.\n",
    "    \"\"\"\n",
    "    average_vector = np.zeros((50,))\n",
    "    for i in range(len(tokens)):\n",
    "        average_vector += get_token_embedding(tokens[i])\n",
    "    average_vector = average_vector / len(tokens)\n",
    "    return average_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "YX_0Ryvlh9Hv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding of ['princess', 'frog'] :\n",
      "  [ 0.19482759  0.11889462 -0.17737214  0.15396611  0.08941954  0.17433513\n",
      "  0.00553212  0.06158997  0.07124736 -0.09829862  0.05330768  0.11427242\n",
      "  0.18295492 -0.03992577  0.05355072  0.06239018 -0.09932238  0.11463517\n",
      " -0.12799442 -0.01127088 -0.05557535 -0.01588819  0.03568342  0.0324892\n",
      "  0.15007959 -0.14938772 -0.20444039  0.06785171 -0.0632048  -0.1077086\n",
      "  0.15069643 -0.00078949  0.03694061  0.15214353  0.01963824 -0.01524018\n",
      " -0.02847135 -0.09666358 -0.03960238 -0.16786506 -0.02946135 -0.01346679\n",
      " -0.04725478 -0.07911661  0.14332134 -0.05626741  0.0072868  -0.33822565\n",
      "  0.07844153 -0.0640892 ]\n"
     ]
    }
   ],
   "source": [
    "def test_vectorize_text():\n",
    "    text = \"The Princess and the Frog\"\n",
    "    tokens = preprocess_text(text)\n",
    "    try:\n",
    "        assert vectorize_text(tokens).shape == (50,), \"Wrong embeddings\"\n",
    "    except NotImplementedError:\n",
    "        print(\"Run this cell after implementation of the above cell!\")\n",
    "    print('Embedding of', tokens, ':\\n ', vectorize_text(tokens))\n",
    "test_vectorize_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D32Qw708mDNS"
   },
   "source": [
    "# 1. Dataset\n",
    "There is a dataset `classification_dataset.zip` file adjacent to this notebook. The data contains more news documents, each one consisting of a title, body, and a category (1: World, 2: Sports, 3: Business, 4: Science/Technology). In the following cells load the dataset in Pandas dataframe format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q4o9FwQ7nBV2"
   },
   "source": [
    "## 1.0. Load in dataframe format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "BNbGcEGxl6qB"
   },
   "outputs": [],
   "source": [
    "def load_dataset(dataset_path):\n",
    "    \"\"\"\n",
    "    Loads the dataset file and returns it in pandas format.\n",
    "\n",
    "    Parameters:\n",
    "        dataset_path (str): path to dataset file\n",
    "\n",
    "    Retuns:\n",
    "        dataset (pd.DataFrame): pandas dataframe object.\n",
    "    \"\"\"\n",
    "    return pd.read_json(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "dHqEWmLsm047"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Every day, cubicle-dwellers get up from their ...</td>\n",
       "      <td>4</td>\n",
       "      <td>MobileAccess Networks Strengthens Signals for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New 1.8-inch hard drives may boost battery lif...</td>\n",
       "      <td>4</td>\n",
       "      <td>Hitachi Drives Consumer Storage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A hearing into allegations of racism against t...</td>\n",
       "      <td>1</td>\n",
       "      <td>Cricket: Zim race probe halted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The prospect that a tropical storm and a hurri...</td>\n",
       "      <td>4</td>\n",
       "      <td>Simultaneous Tropical Storms are Very Rare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Second seed Jiri Novak and number three Guille...</td>\n",
       "      <td>2</td>\n",
       "      <td>NOVAK AND CANAS SET UP SHOWDOWN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  category  \\\n",
       "0  Every day, cubicle-dwellers get up from their ...         4   \n",
       "1  New 1.8-inch hard drives may boost battery lif...         4   \n",
       "2  A hearing into allegations of racism against t...         1   \n",
       "3  The prospect that a tropical storm and a hurri...         4   \n",
       "4  Second seed Jiri Novak and number three Guille...         2   \n",
       "\n",
       "                                               title  \n",
       "0  MobileAccess Networks Strengthens Signals for ...  \n",
       "1                    Hitachi Drives Consumer Storage  \n",
       "2                     Cricket: Zim race probe halted  \n",
       "3         Simultaneous Tropical Storms are Very Rare  \n",
       "4                    NOVAK AND CANAS SET UP SHOWDOWN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = load_dataset(\"classification_dataset/train.json\")\n",
    "val_dataset = load_dataset(\"classification_dataset/validation.json\")\n",
    "\n",
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q-XuQoVlnOZ5"
   },
   "source": [
    "## 1.1. Vectorize dataset\n",
    "In this part, for getting the GloVe embedding, simply concatenate the text in the title and body of each entry and consider them as one text input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "3sdW9-ncnHYc"
   },
   "outputs": [],
   "source": [
    "def vectorize_dataset(dataset):\n",
    "    \"\"\"\n",
    "    Vectorize all text inputs of the dataset. Each vector should be\n",
    "    the average GloVe embedding of the text presented in its \n",
    "    respective row.\n",
    "    The output will be in form of pandas with one additional column\n",
    "    named `embedding`.\n",
    "\n",
    "    Parameters:\n",
    "        dataset (pd.DataFrame): path to dataset file\n",
    "\n",
    "    Retuns:\n",
    "        new_dataset (pd.DataFrame): new dataset with the added embeddings column\n",
    "    \"\"\"\n",
    "    vectors = list()\n",
    "    for i in range(len(dataset)):\n",
    "        vectors.append(vectorize_text(preprocess_text(dataset['title'][i] + dataset['body'][i])))\n",
    "    \n",
    "    dataset['Embedding'] = vectors\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "zSlocu40oTx2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>Embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Every day, cubicle-dwellers get up from their ...</td>\n",
       "      <td>4</td>\n",
       "      <td>MobileAccess Networks Strengthens Signals for ...</td>\n",
       "      <td>[0.04450523899868131, 0.03620941671761102, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New 1.8-inch hard drives may boost battery lif...</td>\n",
       "      <td>4</td>\n",
       "      <td>Hitachi Drives Consumer Storage</td>\n",
       "      <td>[0.01512077826863298, -0.02261329721659422, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A hearing into allegations of racism against t...</td>\n",
       "      <td>1</td>\n",
       "      <td>Cricket: Zim race probe halted</td>\n",
       "      <td>[-0.030633848692689623, -0.05615816019209368, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The prospect that a tropical storm and a hurri...</td>\n",
       "      <td>4</td>\n",
       "      <td>Simultaneous Tropical Storms are Very Rare</td>\n",
       "      <td>[0.03878044509328902, 0.020403445764289548, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Second seed Jiri Novak and number three Guille...</td>\n",
       "      <td>2</td>\n",
       "      <td>NOVAK AND CANAS SET UP SHOWDOWN</td>\n",
       "      <td>[-0.040298306429758665, 0.015299352444708347, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  category  \\\n",
       "0  Every day, cubicle-dwellers get up from their ...         4   \n",
       "1  New 1.8-inch hard drives may boost battery lif...         4   \n",
       "2  A hearing into allegations of racism against t...         1   \n",
       "3  The prospect that a tropical storm and a hurri...         4   \n",
       "4  Second seed Jiri Novak and number three Guille...         2   \n",
       "\n",
       "                                               title  \\\n",
       "0  MobileAccess Networks Strengthens Signals for ...   \n",
       "1                    Hitachi Drives Consumer Storage   \n",
       "2                     Cricket: Zim race probe halted   \n",
       "3         Simultaneous Tropical Storms are Very Rare   \n",
       "4                    NOVAK AND CANAS SET UP SHOWDOWN   \n",
       "\n",
       "                                           Embedding  \n",
       "0  [0.04450523899868131, 0.03620941671761102, 0.0...  \n",
       "1  [0.01512077826863298, -0.02261329721659422, 0....  \n",
       "2  [-0.030633848692689623, -0.05615816019209368, ...  \n",
       "3  [0.03878044509328902, 0.020403445764289548, 0....  \n",
       "4  [-0.040298306429758665, 0.015299352444708347, ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_vect = vectorize_dataset(train_dataset)\n",
    "val_dataset_vect = vectorize_dataset(val_dataset)\n",
    "\n",
    "train_dataset_vect.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t-XIw5vDps7P"
   },
   "source": [
    "# 2. KNN\n",
    "\n",
    "In the following cells, you are asked to implement the KNN algorithm. \n",
    "\n",
    "You will write a function that gets the training samples and a specific query and a parameter `k` defining the count of nearest neighbours.\n",
    "\n",
    "The function should predict the query's label based on the top `k` nearest embedding vectors labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kkbu4FJ2wX0A"
   },
   "source": [
    "## 2.0. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "rT5AYjazvZ6e"
   },
   "outputs": [],
   "source": [
    "def get_distance(v1, v2):\n",
    "    \"\"\"\n",
    "    Returns the euclidian distance between two vectors.\n",
    "\n",
    "    Parameters:\n",
    "        v1 (np.array) : vector 1\n",
    "        v2 (np.array) : vector 2\n",
    "\n",
    "    Returns:\n",
    "        dist (float) : euclidian distance between the vectors\n",
    "    \"\"\"\n",
    "    norm = np.linalg.norm(v1)\n",
    "    if norm != 1:\n",
    "        v1 = v1 / norm\n",
    "    norm = np.linalg.norm(v2)\n",
    "    if norm != 1:\n",
    "        v2 = v2 / norm\n",
    "    return np.linalg.norm(v1 - v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "9MxDjvSlvyOW"
   },
   "outputs": [],
   "source": [
    "def KNN(query, k, train_dataset):\n",
    "    \"\"\"\n",
    "    Predict the query label based on its `k` nearest neighbours in the training set.\n",
    "\n",
    "    Parameters:\n",
    "        query (np.array) : input query embedding to predict.\n",
    "        k (int) : defines the nearest neighbours to considered\n",
    "        train_dataset (pd.DataFrame) : training dataset samples\n",
    "\n",
    "    Returns:\n",
    "        label (int) : Predicted label\n",
    "    \"\"\"\n",
    "    query_vector = vectorize_text(query)\n",
    "    distances = dict()\n",
    "    for i in range(len(train_dataset)):\n",
    "        distances[i] = get_distance(query_vector, train_dataset['Embedding'][i])\n",
    "    top_k = {key: value for key, value in sorted(distances.items(), key=lambda item: item[1])}\n",
    "    count = 0\n",
    "    classes = list()\n",
    "    for key in top_k:\n",
    "        classes.append(train_dataset['category'][key])\n",
    "        count += 1\n",
    "        if count == k:\n",
    "            break\n",
    "    return max(set(classes), key = classes.count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "z5URA-NKpxKA"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ten\\AppData\\Local\\Temp/ipykernel_15320/3839470352.py:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  v1 = v1 / norm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "def test_KNN():\n",
    "    text = \"The Princess and the Frog\"\n",
    "    tokens = preprocess_text(text)\n",
    "    query = vectorize_text(tokens)\n",
    "    try:\n",
    "        print(KNN(query, 10, train_dataset_vect))\n",
    "    except NotImplementedError:\n",
    "        print(\"Run this cell after implementation of the above cell!\")\n",
    "\n",
    "test_KNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jwp5ipvewoLJ"
   },
   "source": [
    "## 2.1. Prediction and Evaluation\n",
    "We will implement a function that gets the validation set and calculates classification metrics on its predictions based on a specific `k`.\n",
    "\n",
    "After that you should report the metrics for `k` values of `{1, 5, 10, 20}` on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "AQynbjlewr9b"
   },
   "outputs": [],
   "source": [
    "def evaluate_KNN(k, val_dataset, train_dataset):\n",
    "    \"\"\"\n",
    "    Evaluate KNN with the given `k` on the validation set.\n",
    "    Then return the classification metrics in a dictionary.\n",
    "    Keys will be the metric name in `str` format and the respective\n",
    "    values are the metric's values.\n",
    "    For example {'f1': 0.65}\n",
    "\n",
    "    Parameters:\n",
    "        k (int) : defines the nearest neighbours to considered\n",
    "        val_dataset (pd.DataFrame) : validation dataset samples\n",
    "        train_dataset (pd.DataFrame) : training dataset samples\n",
    "\n",
    "    Returns:\n",
    "        metrics (dict) : dictionary containing prediction based on metrics.\n",
    "    \"\"\"\n",
    "    classes = list()\n",
    "    for i in tqdm(range(len(val_dataset))):\n",
    "        query = preprocess_text(val_dataset['title'][i] + val_dataset['body'][i])\n",
    "        classes.append(KNN(query, k, train_dataset))\n",
    "    y_true = list()\n",
    "    y_predicted = list()\n",
    "    for i in range(1, 5):\n",
    "        y_true_i = list()\n",
    "        y_predicted_i = list()\n",
    "        for j in range(len(classes)):\n",
    "            if val_dataset['category'][j] == i:\n",
    "                y_true_i.append(True)\n",
    "            else:\n",
    "                y_true_i.append(False)\n",
    "            if classes[j] == i:\n",
    "                y_predicted_i.append(True)\n",
    "            else:\n",
    "                y_predicted_i.append(False)\n",
    "        y_true.append(y_true_i)\n",
    "        y_predicted.append(y_predicted_i)\n",
    "    metrics = dict()\n",
    "    metrics['accuracy'] = get_accuracy(classes, list(val_dataset['category']))\n",
    "    metrics['micro-precision'] = get_precision(y_true, y_predicted, 'micro')\n",
    "    metrics['macro-precision'] = get_precision(y_true, y_predicted, 'macro')\n",
    "    metrics['micro-recall'] = get_recall(y_true, y_predicted, 'micro')\n",
    "    metrics['macro-recall'] = get_recall(y_true, y_predicted, 'macro')\n",
    "    metrics['micro-f1'] = get_f1_score(y_true, y_predicted, 'micro')\n",
    "    metrics['macro-f1'] = get_f1_score(y_true, y_predicted, 'macro')\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [27:03<00:00,  1.85it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [26:17<00:00,  1.90it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [26:11<00:00,  1.91it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [25:48<00:00,  1.94it/s]\n"
     ]
    }
   ],
   "source": [
    "metrics_for_each_k = dict()\n",
    "for k in [1, 5, 10, 20]:\n",
    "    try:\n",
    "        metrics_for_each_k[k] = evaluate_KNN(k, val_dataset_vect, train_dataset_vect)\n",
    "    except NotImplementedError:\n",
    "        print(\"Run this cell after implementation of the above cell!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KnklQTcVyMFn"
   },
   "source": [
    "## 2.2. Sklearn KNN\n",
    "In the following cell use the Sklearn KNN on your training set and then compare its results with your own results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Z_p0ExoVyHN_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My code results:\n",
      "\n",
      "k = 1 : \n",
      "Accuracy:  0.8443333333333334\n",
      "Micro-precision:  0.8443333333333334\n",
      "Macro-precision:  0.8447431874464275\n",
      "Micro-recall:  0.8443333333333334\n",
      "Macro-recall:  0.8443333333333334\n",
      "Micro-f1:  0.8443333333333334\n",
      "Macro-f1:  0.8445382106643672\n",
      "\n",
      "\n",
      "k = 5 : \n",
      "Accuracy:  0.8763333333333333\n",
      "Micro-precision:  0.8763333333333333\n",
      "Macro-precision:  0.8756541043207571\n",
      "Micro-recall:  0.8763333333333333\n",
      "Macro-recall:  0.8763333333333333\n",
      "Micro-f1:  0.8763333333333333\n",
      "Macro-f1:  0.8759935871617028\n",
      "\n",
      "\n",
      "k = 10 : \n",
      "Accuracy:  0.8813333333333333\n",
      "Micro-precision:  0.8813333333333333\n",
      "Macro-precision:  0.8810118432236447\n",
      "Micro-recall:  0.8813333333333333\n",
      "Macro-recall:  0.8813333333333334\n",
      "Micro-f1:  0.8813333333333333\n",
      "Macro-f1:  0.8811725589550932\n",
      "\n",
      "\n",
      "k = 20 : \n",
      "Accuracy:  0.8733333333333333\n",
      "Micro-precision:  0.8733333333333333\n",
      "Macro-precision:  0.8731380598532117\n",
      "Micro-recall:  0.8733333333333333\n",
      "Macro-recall:  0.8733333333333334\n",
      "Micro-f1:  0.8733333333333333\n",
      "Macro-f1:  0.8732356856764799\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sklearn knn results:\n",
      "\n",
      "k = 1 : \n",
      "Accuracy:  0.8403333333333334\n",
      "Micro-precision:  0.8403333333333334\n",
      "Macro-precision:  0.840753918353911\n",
      "Micro-recall:  0.8403333333333334\n",
      "Macro-recall:  0.8403333333333334\n",
      "Micro-f1:  0.8403333333333334\n",
      "Macro-f1:  0.8405435732313146\n",
      "\n",
      "\n",
      "k = 5 : \n",
      "Accuracy:  0.875\n",
      "Micro-precision:  0.875\n",
      "Macro-precision:  0.8748651958480057\n",
      "Micro-recall:  0.875\n",
      "Macro-recall:  0.875\n",
      "Micro-f1:  0.875\n",
      "Macro-f1:  0.8749325927315573\n",
      "\n",
      "\n",
      "k = 10 : \n",
      "Accuracy:  0.8836666666666667\n",
      "Micro-precision:  0.8836666666666667\n",
      "Macro-precision:  0.8843154718591492\n",
      "Micro-recall:  0.8836666666666667\n",
      "Macro-recall:  0.8836666666666667\n",
      "Micro-f1:  0.8836666666666668\n",
      "Macro-f1:  0.883990950215275\n",
      "\n",
      "\n",
      "k = 20 : \n",
      "Accuracy:  0.8773333333333333\n",
      "Micro-precision:  0.8773333333333333\n",
      "Macro-precision:  0.8783540725045631\n",
      "Micro-recall:  0.8773333333333333\n",
      "Macro-recall:  0.8773333333333333\n",
      "Micro-f1:  0.8773333333333333\n",
      "Macro-f1:  0.8778434061951544\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: use sklearn KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "metrics_for_each_k_2 = dict()\n",
    "for k in [1, 5, 10, 20]:\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(list(train_dataset_vect['Embedding']), list(train_dataset_vect['category']))\n",
    "    prediction = knn.predict(list(val_dataset_vect['Embedding']))\n",
    "    y_true = list()\n",
    "    y_predicted = list()\n",
    "    for i in range(1, 5):\n",
    "        y_true_i = list()\n",
    "        y_predicted_i = list()\n",
    "        for j in range(len(prediction)):\n",
    "            if val_dataset_vect['category'][j] == i:\n",
    "                y_true_i.append(True)\n",
    "            else:\n",
    "                y_true_i.append(False)\n",
    "            if prediction[j] == i:\n",
    "                y_predicted_i.append(True)\n",
    "            else:\n",
    "                y_predicted_i.append(False)\n",
    "        y_true.append(y_true_i)\n",
    "        y_predicted.append(y_predicted_i)\n",
    "    metrics = dict()\n",
    "    metrics['accuracy'] = get_accuracy(prediction, list(val_dataset_vect['category']))\n",
    "    metrics['micro-precision'] = get_precision(y_true, y_predicted, 'micro')\n",
    "    metrics['macro-precision'] = get_precision(y_true, y_predicted, 'macro')\n",
    "    metrics['micro-recall'] = get_recall(y_true, y_predicted, 'micro')\n",
    "    metrics['macro-recall'] = get_recall(y_true, y_predicted, 'macro')\n",
    "    metrics['micro-f1'] = get_f1_score(y_true, y_predicted, 'micro')\n",
    "    metrics['macro-f1'] = get_f1_score(y_true, y_predicted, 'macro')\n",
    "    metrics_for_each_k_2[k] = metrics\n",
    "\n",
    "print('My code results:\\n')\n",
    "for k in [1, 5, 10, 20]:\n",
    "    print('k =', k, ': ')\n",
    "    print('Accuracy: ', metrics_for_each_k[k]['accuracy'])\n",
    "    print('Micro-precision: ', metrics_for_each_k[k]['micro-precision'])\n",
    "    print('Macro-precision: ', metrics_for_each_k[k]['macro-precision'])\n",
    "    print('Micro-recall: ', metrics_for_each_k[k]['micro-recall'])\n",
    "    print('Macro-recall: ', metrics_for_each_k[k]['macro-recall'])\n",
    "    print('Micro-f1: ', metrics_for_each_k[k]['micro-f1'])\n",
    "    print('Macro-f1: ', metrics_for_each_k[k]['macro-f1'])\n",
    "    print('\\n')\n",
    "print('\\n\\n\\nsklearn knn results:\\n')\n",
    "for k in [1, 5, 10, 20]:\n",
    "    print('k =', k, ': ')\n",
    "    print('Accuracy: ', metrics_for_each_k_2[k]['accuracy'])\n",
    "    print('Micro-precision: ', metrics_for_each_k_2[k]['micro-precision'])\n",
    "    print('Macro-precision: ', metrics_for_each_k_2[k]['macro-precision'])\n",
    "    print('Micro-recall: ', metrics_for_each_k_2[k]['micro-recall'])\n",
    "    print('Macro-recall: ', metrics_for_each_k_2[k]['macro-recall'])\n",
    "    print('Micro-f1: ', metrics_for_each_k_2[k]['micro-f1'])\n",
    "    print('Macro-f1: ', metrics_for_each_k_2[k]['macro-f1'])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6t8a1mUryeLs"
   },
   "source": [
    "## 2.3. Speed up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "So4lPdNLylFq"
   },
   "source": [
    "As you probably have noticed, sklearn performs the KNN much faster than our implemented KNN.\n",
    "One of the main reasons is that it uses LSH. Read about this algorithm and write down a paragraph about it, explain why it will boost the speed of the KNN and how it should be implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NS1i1_Ouzavn"
   },
   "source": [
    "Write your answer here (fa or en)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CipwYIugzgf2"
   },
   "source": [
    "این الگوریتم، داده ها را به گونه ای هش میکند که داده هایی که نزدیک به هم هستند با احتمال زیادی به یک جایگاه یکسان هش شوند. در نتیجه از این طریق میتوان داک های مشابه را در یک بخش هش کرد و دسترسی به آنها سریع تر میشود و سرعت اجرای الگوریتم نزدیک ترین همسایه ها افزایش می یابد"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D0gOxRCkuQ_V"
   },
   "source": [
    "# 3. SVM Model\n",
    "Now train an SVM model using sklearn library. For more information read [SVC documentation](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hjITvUh3uQ_V"
   },
   "source": [
    "## 3.1. Choose hyperparameters\n",
    "For choosing the best hyperparameters, you can use [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "CJrXJMC1uQ_V"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'C': 10, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\"\"\"\n",
    "For choosing proper hyperparameters for SVC model, we should split train dataset into two parts:\n",
    "1- train set 2- validation set. Then train model on train set and measure performance on validation set. \n",
    "Finally we should choose hyperparameters that has the best performance on validation set.\n",
    "We can do these process using GridSearchCV.\n",
    "\"\"\"\n",
    "#Specify different values for different hyperparameters for GridSearchCV to choose among them\n",
    "parameters = {\n",
    "    'kernel':('linear', 'poly', 'rbf'),\n",
    "    'C':[1,10,100]\n",
    "}\n",
    "\n",
    "svc = SVC()\n",
    "clf = GridSearchCV(svc, parameters)\n",
    "#Get the best set of hyperparameters\n",
    "#TODO\n",
    "print()\n",
    "X_train, X_test, y_train, y_test = train_test_split(list(train_dataset_vect['Embedding']), list(train_dataset_vect['category']), test_size=0.5)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9wIZ6n4kuQ_W"
   },
   "source": [
    "## 3.2. Train SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "GrJgdSzzuQ_W"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train SVC model with the chosen hyperparameters\n",
    "#TODO\n",
    "svc = SVC(kernel=clf.best_params_['kernel'], C=clf.best_params_['C'])\n",
    "svc.fit(list(train_dataset_vect['Embedding']), list(train_dataset_vect['category']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hjjHzb7AuQ_W"
   },
   "source": [
    "## 3.3. Measure performance of the SVM model\n",
    "In this section, first get predictions on the test set. Then, obtain the evaluation metrics using both what you implemented from scrach in the Model evaluation part and built-in functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "gV8CL1psuQ_W"
   },
   "outputs": [],
   "source": [
    "#Get prediction on test set\n",
    "#TODO\n",
    "prediction = svc.predict(list(val_dataset_vect['Embedding']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "PPWXs4vuuQ_W"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With sklearn metric functions: \n",
      "Accuracy:  0.885\n",
      "Micro-Precision:  0.885\n",
      "Macro-Precision:  0.8852500363605169\n",
      "Micro-Recall:  0.885\n",
      "Macro-Recall:  0.885\n",
      "Micro-F1:  0.885\n",
      "Macro-F1:  0.8847599763073059\n",
      "With our implemented metric functions: \n",
      "Accuracy:  0.885\n",
      "Micro-Precision:  0.885\n",
      "Macro-Precision:  0.8852500363605169\n",
      "Micro-Recall:  0.885\n",
      "Macro-Recall:  0.885\n",
      "Micro-F1:  0.885\n",
      "Macro-F1:  0.8851250005222495\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "\"\"\"\n",
    "Measure model's accuracy, f1_score, precision, and recall both using sklearn library and functions you have\n",
    "implemented in the Model evaluation part. Then compare the SVM model's performance with other models you have\n",
    "implemented on given dataset. \n",
    "\"\"\"\n",
    "#TODO\n",
    "y_true = list()\n",
    "y_predicted = list()\n",
    "for i in range(1, 5):\n",
    "    y_true_i = list()\n",
    "    y_predicted_i = list()\n",
    "    for j in range(len(prediction)):\n",
    "        if val_dataset_vect['category'][j] == i:\n",
    "            y_true_i.append(True)\n",
    "        else:\n",
    "            y_true_i.append(False)\n",
    "        if prediction[j] == i:\n",
    "            y_predicted_i.append(True)\n",
    "        else:\n",
    "            y_predicted_i.append(False)\n",
    "    y_true.append(y_true_i)\n",
    "    y_predicted.append(y_predicted_i)\n",
    "\n",
    "print('With sklearn metric functions: ')\n",
    "print('Accuracy: ', accuracy_score(list(val_dataset_vect['category']), prediction))\n",
    "print('Micro-Precision: ', precision_score(list(val_dataset_vect['category']), prediction, average='micro'))\n",
    "print('Macro-Precision: ', precision_score(list(val_dataset_vect['category']), prediction, average='macro'))\n",
    "print('Micro-Recall: ', recall_score(list(val_dataset_vect['category']), prediction, average='micro'))\n",
    "print('Macro-Recall: ', recall_score(list(val_dataset_vect['category']), prediction, average='macro'))\n",
    "print('Micro-F1: ', f1_score(list(val_dataset_vect['category']), prediction, average='micro'))\n",
    "print('Macro-F1: ', f1_score(list(val_dataset_vect['category']), prediction, average='macro'))\n",
    "      \n",
    "print('With our implemented metric functions: ')\n",
    "print('Accuracy: ', get_accuracy(prediction, list(val_dataset_vect['category'])))\n",
    "print('Micro-Precision: ', get_precision(y_true, y_predicted, 'micro'))\n",
    "print('Macro-Precision: ', get_precision(y_true, y_predicted, 'macro'))\n",
    "print('Micro-Recall: ', get_recall(y_true, y_predicted, 'micro'))\n",
    "print('Macro-Recall: ', get_recall(y_true, y_predicted, 'macro'))\n",
    "print('Micro-F1: ', get_f1_score(y_true, y_predicted, 'micro'))\n",
    "print('Macro-F1: ', get_f1_score(y_true, y_predicted, 'macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "نتیجه به دست آمده به صورت زیر است\n",
    "\n",
    "accuracy(svm) > accuracy(KNN, k=20|10|5|1)\n",
    "\n",
    "های 10 و 20 بسیار به اس وی ام نزدیک هستند k البته مقادیر به ازای "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qiFGLtLIuQ_W"
   },
   "source": [
    "## 4. Naive Bayes\n",
    "In this section, you are asked to implement the Naive Bayes classifier on the given data from scratch.\n",
    "In your implementation, also use Laplacian smoothing.In this approach, you shall calculate the probabilty of each term belonging to each category as follows:\n",
    "$$P[t, c] = {\\alpha + T_{t, c} \\over \\alpha|V| + \\sum_{t \\in V} T_{t, c}},$$\n",
    "where $t$ represents each term, $V$ the whole vocabulary, $c$ each categroy, $\\alpha$ the smoothing factor, and $T_{t, c}$ the frequency of the term $t$ in the class $c$.\n",
    "\n",
    "Also, to avoid calculation errors in multiplication of probabilities over terms, you may use the log of probabilites for the final score of a document. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YYrF4C9PuQ_W"
   },
   "source": [
    "## 4.1 Prediction\n",
    "Here, implement yout Naive Bayes classifier. Note that this part does not use glove embeddings, but uses the original documents in the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "OTktQY1euQ_W"
   },
   "outputs": [],
   "source": [
    "def naive_bayes(train_dataset, title_weight, body_weight, smoothing_factor, val_dataset):\n",
    "    \"\"\"\n",
    "    This function performs Naive Bayes classification. First, build term-per-category counts as described in the\n",
    "    folrmulation above for the training data. Notice the body and title weights in counting terms in the training\n",
    "    data, that is the number of occurrence for terms in the title is multiplied by title_weight and likewise for\n",
    "    body_weight). Then using term-per-category counts obtained, classify the documents in the validation dataset.\n",
    "\n",
    "    Parameters:\n",
    "        train_dataset (pd.DataFrame) : training dataset samples\n",
    "        title_weight (int): weight for each term occurrence in the title of eash sample\n",
    "        body_weight (int): weight for each term occurrence in the body of eash sample\n",
    "        smoothing_factor (float): Laplacian smoothing factor for Naive Bayes\n",
    "        val_dataset (pd.DataFrame) : validation dataset samples\n",
    "    Returns:\n",
    "        category (list) : list of predicted categories for validation data\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    term_frequency = dict()\n",
    "    number_of_all_terms_in_a_class = np.zeros(5)\n",
    "    for i in range(len(train_dataset)):\n",
    "        if title_weight != 0:\n",
    "            title_tokens = preprocess_text(train_dataset['title'][i])\n",
    "            number_of_all_terms_in_a_class[train_dataset['category'][i]] += title_weight * len(title_tokens)\n",
    "            for token in title_tokens:\n",
    "                if token in term_frequency:\n",
    "                    term_frequency[token][train_dataset['category'][i]] += title_weight\n",
    "                else:\n",
    "                    term_frequency[token] = np.zeros(5)\n",
    "                    term_frequency[token][train_dataset['category'][i]] = title_weight\n",
    "        if body_weight != 0:\n",
    "            body_tokens = preprocess_text(train_dataset['body'][i])\n",
    "            number_of_all_terms_in_a_class[train_dataset['category'][i]] += body_weight * len(body_tokens)\n",
    "            for token in body_tokens:\n",
    "                if token in term_frequency:\n",
    "                    term_frequency[token][train_dataset['category'][i]] += body_weight\n",
    "                else:\n",
    "                    term_frequency[token] = np.zeros(5)\n",
    "                    term_frequency[token][train_dataset['category'][i]] = body_weight\n",
    "    predictions = list()\n",
    "    smoothing_factor_vector = np.array([0, smoothing_factor, smoothing_factor, smoothing_factor, smoothing_factor])\n",
    "    for i in range(len(val_dataset)):\n",
    "        probability = np.zeros(5)\n",
    "        if title_weight != 0:\n",
    "            title_tokens = preprocess_text(val_dataset['title'][i])\n",
    "            for token in title_tokens:\n",
    "                term_frequency_for_token = np.zeros(5)\n",
    "                if token in term_frequency:\n",
    "                    term_frequency_for_token = term_frequency[token]\n",
    "                probability += title_weight * np.log(np.divide((smoothing_factor_vector + term_frequency_for_token), (len(term_frequency) * smoothing_factor_vector + number_of_all_terms_in_a_class)))\n",
    "        if body_weight != 0:\n",
    "            body_tokens = preprocess_text(val_dataset['body'][i])\n",
    "            for token in body_tokens:\n",
    "                term_frequency_for_token = np.zeros(5)\n",
    "                if token in term_frequency:\n",
    "                    term_frequency_for_token = term_frequency[token]\n",
    "                probability += body_weight * np.log(np.divide((smoothing_factor_vector + term_frequency_for_token), (len(term_frequency) * smoothing_factor_vector + number_of_all_terms_in_a_class)))\n",
    "        probability[0] = -np.Inf\n",
    "        predictions.append(np.argmax(probability))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FLxBuVbauQ_X"
   },
   "source": [
    "## 4.2 Evaluation\n",
    "In this part, we will consider different weighting schemes for evaluation on our validation dataset as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "tttLednwuQ_X"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ten\\AppData\\Local\\Temp/ipykernel_15320/3419566134.py:49: RuntimeWarning: invalid value encountered in true_divide\n",
      "  probability += title_weight * np.log(np.divide((smoothing_factor_vector + term_frequency_for_token), (len(term_frequency) * smoothing_factor_vector + number_of_all_terms_in_a_class)))\n",
      "C:\\Users\\ten\\AppData\\Local\\Temp/ipykernel_15320/3419566134.py:56: RuntimeWarning: invalid value encountered in true_divide\n",
      "  probability += body_weight * np.log(np.divide((smoothing_factor_vector + term_frequency_for_token), (len(term_frequency) * smoothing_factor_vector + number_of_all_terms_in_a_class)))\n"
     ]
    }
   ],
   "source": [
    "val_predictions = []\n",
    "# Considering title words only\n",
    "val_predictions.append(naive_bayes(train_dataset, 1, 0, 1.5, val_dataset))\n",
    "\n",
    "# Considering body words only\n",
    "val_predictions.append(naive_bayes(train_dataset, 0, 1, 1.5, val_dataset))\n",
    "\n",
    "# Considering title and body words equally\n",
    "val_predictions.append(naive_bayes(train_dataset, 1, 1, 1.5, val_dataset))\n",
    "\n",
    "# Considering title words twice more important than body words\n",
    "val_predictions.append(naive_bayes(train_dataset, 2, 1, 1.5, val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "pXU22XFfuQ_X"
   },
   "outputs": [],
   "source": [
    "def evaluate_naive_bayes(val_dataset, val_prediction):\n",
    "    \"\"\"\n",
    "    Calculates the metrics implemented in Model Evaluation for the Naive Bayes classifier.\n",
    "    Parameters:\n",
    "        val_dataset (pd.DataFrame) : validation dataset samples\n",
    "        val_prediction (list) :list of predicted categories for validation data\n",
    "\n",
    "    Returns:\n",
    "        metrics (dict) : dictionary of the metrics on the given predictions\n",
    "    \"\"\"\n",
    "    y_true = list()\n",
    "    y_predicted = list()\n",
    "    for i in range(1, 5):\n",
    "        y_true_i = list()\n",
    "        y_predicted_i = list()\n",
    "        for j in range(len(prediction)):\n",
    "            if val_dataset['category'][j] == i:\n",
    "                y_true_i.append(True)\n",
    "            else:\n",
    "                y_true_i.append(False)\n",
    "            if val_prediction[j] == i:\n",
    "                y_predicted_i.append(True)\n",
    "            else:\n",
    "                y_predicted_i.append(False)\n",
    "        y_true.append(y_true_i)\n",
    "        y_predicted.append(y_predicted_i)\n",
    "    metrics = dict()\n",
    "    metrics['accuracy'] = get_accuracy(val_prediction, list(val_dataset_vect['category']))\n",
    "    metrics['micro-precision'] = get_precision(y_true, y_predicted, 'micro')\n",
    "    metrics['macro-precision'] = get_precision(y_true, y_predicted, 'macro')\n",
    "    metrics['micro-recall'] = get_recall(y_true, y_predicted, 'micro')\n",
    "    metrics['macro-recall'] = get_recall(y_true, y_predicted, 'macro')\n",
    "    metrics['micro-f1'] = get_f1_score(y_true, y_predicted, 'micro')\n",
    "    metrics['macro-f1'] = get_f1_score(y_true, y_predicted, 'macro')\n",
    "    return metrics\n",
    "    #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "WP8_VFvruQ_X"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'accuracy': 0.824, 'micro-precision': 0.824, 'macro-precision': 0.8237543419953393, 'micro-recall': 0.824, 'macro-recall': 0.8240000000000001, 'micro-f1': 0.824, 'macro-f1': 0.8238771526855179}, {'accuracy': 0.8836666666666667, 'micro-precision': 0.8836666666666667, 'macro-precision': 0.8827922383215231, 'micro-recall': 0.8836666666666667, 'macro-recall': 0.8836666666666667, 'micro-f1': 0.8836666666666668, 'macro-f1': 0.8832292360653603}, {'accuracy': 0.8993333333333333, 'micro-precision': 0.8993333333333333, 'macro-precision': 0.8988576942887748, 'micro-recall': 0.8993333333333333, 'macro-recall': 0.8993333333333333, 'micro-f1': 0.8993333333333333, 'macro-f1': 0.8990954509054736}, {'accuracy': 0.899, 'micro-precision': 0.899, 'macro-precision': 0.8984458801745248, 'micro-recall': 0.899, 'macro-recall': 0.899, 'micro-f1': 0.899, 'macro-f1': 0.8987228546747378}]\n"
     ]
    }
   ],
   "source": [
    "metrics = []\n",
    "for val_prediction in val_predictions:\n",
    "    metrics.append(evaluate_naive_bayes(val_dataset, val_prediction))\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wWq_OpsnuQ_X"
   },
   "source": [
    "## 4.3 Analysis\n",
    "Answer the following questions:\n",
    "1. Compare the weighting scenrios used above given the resulting metrics. (fa or en)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rOrLoi6KuQ_X"
   },
   "source": [
    "مشاهده میکنیم که به ازای حالت اول که فقط عنوان ها را لحاظ میکنیم به مقدار های کمتری به نسبت حالات دیگر دست پیدا میکنیم. اما در باقی حالات متریک های به دست آمده تقریبا مساوی یکدیگر است اما در حالتی که فقط بدنه را لحاظ میکنیم کمی کمتر از دو حالتی است که هم عنوان و هم بدنه را لحاظ میکنیم. همچنین در بین دو حالتی که هم بدنه و هم عنوان را لحاظ میکنیم مقدار دقت در حالتی که عنوان ضریب 2 دارد بیشتر است اما مقدار پرسیژن و ریکال در حالت با ضرایب مساوی کمی بیشتر است"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "00vburVYuQ_X"
   },
   "source": [
    "2. Explain the reason for using the smoothing factor as descrbied above. (fa or en)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NOtY5Gc3uQ_X"
   },
   "source": [
    "اگر این ضریب را اضافه نکنیم کوئری ما ترمی داشته باشد که در یک کلاس ظاهر نشده باشد، احتمال حضور در آن کلاس صفر خواهد شد و به باقی ترم ها وابسته نخواهد بود و اگر ترمی وجود داشته باشد که در هیچ کلاسی نبوده باشد احتمال حضور در همه ی کلاس ها صفر خواهد شد که قابل قبول نیست"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
